{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайные леса\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n",
    "\n",
    "В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import gini, entropy, gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (2 балла)\n",
    "Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n",
    "\n",
    "Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n",
    "\n",
    "#### Методы\n",
    "`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n",
    "\n",
    "`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n",
    "\n",
    "`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n",
    "\n",
    "`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n",
    "\n",
    "`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n",
    "\n",
    "#### Параметры конструктора\n",
    "`n_estimators` - количество используемых для предсказания деревьев.\n",
    "\n",
    "Остальное - параметры деревьев.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
    "\n",
    "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (2 балла)\n",
    "Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n",
    "\n",
    "Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import feature_importance\n",
    "\n",
    "\n",
    "def most_important_features(importance, names, k=20):\n",
    "    idicies = np.argsort(importance)[::-1][:k]\n",
    "    return np.array(names)[idicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev.daniil.bakushkin/Desktop/ML/Practices/hw_9 [Random Forest]/dev/task.py:207: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  predictions = stats.mode(predictions, axis=1)[0].reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Importance: [0.001814678091590638, 0.0012539244413147799, 0.16793008641519314, 0.1472846195648635, 0.32104976412246156, -0.0013203271999341348]\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "\n",
    "def synthetic_dataset(size):\n",
    "    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3,\n",
    "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n",
    "    y = [i % 3 for i in range(size)]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n",
    "print(\"Importance:\", feature_importance(rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (3 балла)\n",
    "Теперь поработаем с реальными данными.\n",
    "\n",
    "Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n",
    "\\\n",
    "Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время.\n",
    "\n",
    "Оценка:\n",
    "1. 1 балл за исправно работающий код\n",
    "2. +1 балл за точность предсказания возростной группы выше 65%\n",
    "3. +1 балл за точность предсказания пола выше 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    dataframe = pandas.read_csv(path, header=0)\n",
    "    dataset = dataframe.values.tolist()\n",
    "    random.shuffle(dataset)\n",
    "    y_age = [row[0] for row in dataset]\n",
    "    y_sex = [row[1] for row in dataset]\n",
    "    X = [row[2:] for row in dataset]\n",
    "\n",
    "    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6923076923076923\n",
      "Most important features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev.daniil.bakushkin/Desktop/ML/Practices/hw_9 [Random Forest]/dev/task.py:207: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  predictions = stats.mode(predictions, axis=1)[0].reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "from task import rfc_age\n",
    "\n",
    "rfc_age.fit(X_train, y_age_train)\n",
    "print(\"Accuracy:\", np.mean(rfc_age.predict(X_test) == y_age_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8436317780580076\n"
     ]
    }
   ],
   "source": [
    "from task import rfc_gender\n",
    "\n",
    "rfc_gender = RandomForestClassifier(n_estimators=10)\n",
    "rfc_gender.fit(X_train, y_sex_train)\n",
    "print(\"Accuracy:\", np.mean(rfc_gender.predict(X_test) == y_sex_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "В качестве аьтернативы попробуем CatBoost. \n",
    "\n",
    "Устаниовить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n",
    "\\\n",
    "Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.333334\n"
     ]
    }
   ],
   "source": [
    "X, y = synthetic_dataset(1000)\n",
    "\n",
    "model = CatBoostClassifier(iterations=100,\n",
    "                           depth=6,\n",
    "                           learning_rate=0.3,\n",
    "                           loss_function='MultiClass',\n",
    "                           verbose=False)\n",
    "\n",
    "model.fit(X, y)\n",
    "preds = model.predict(X)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(preds == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (3 балла)\n",
    "Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются.\n",
    "\n",
    "Оценка:\n",
    "1. 1 балл за исправно работающий код\n",
    "2. +1 балл за точность предсказания возростной группы выше 65%\n",
    "3. +1 балл за точность предсказания пола выше 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
    "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train,\n",
    "                                                                                     train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5782867\ttotal: 61.3ms\tremaining: 3s\n",
      "1:\tlearn: 0.5202976\ttotal: 294ms\tremaining: 7.06s\n",
      "2:\tlearn: 0.4731461\ttotal: 364ms\tremaining: 5.71s\n",
      "3:\tlearn: 0.4454966\ttotal: 449ms\tremaining: 5.17s\n",
      "4:\tlearn: 0.4200515\ttotal: 527ms\tremaining: 4.74s\n",
      "5:\tlearn: 0.4013925\ttotal: 605ms\tremaining: 4.43s\n",
      "6:\tlearn: 0.3877014\ttotal: 684ms\tremaining: 4.2s\n",
      "7:\tlearn: 0.3732214\ttotal: 760ms\tremaining: 3.99s\n",
      "8:\tlearn: 0.3644366\ttotal: 845ms\tremaining: 3.85s\n",
      "9:\tlearn: 0.3529011\ttotal: 919ms\tremaining: 3.68s\n",
      "10:\tlearn: 0.3442580\ttotal: 1.01s\tremaining: 3.57s\n",
      "11:\tlearn: 0.3366976\ttotal: 1.1s\tremaining: 3.47s\n",
      "12:\tlearn: 0.3301906\ttotal: 1.18s\tremaining: 3.35s\n",
      "13:\tlearn: 0.3242020\ttotal: 1.25s\tremaining: 3.21s\n",
      "14:\tlearn: 0.3191568\ttotal: 1.32s\tremaining: 3.09s\n",
      "15:\tlearn: 0.3144719\ttotal: 1.42s\tremaining: 3.02s\n",
      "16:\tlearn: 0.3074755\ttotal: 1.49s\tremaining: 2.9s\n",
      "17:\tlearn: 0.3024600\ttotal: 1.56s\tremaining: 2.77s\n",
      "18:\tlearn: 0.2982452\ttotal: 1.62s\tremaining: 2.64s\n",
      "19:\tlearn: 0.2943172\ttotal: 1.69s\tremaining: 2.53s\n",
      "20:\tlearn: 0.2902580\ttotal: 1.75s\tremaining: 2.41s\n",
      "21:\tlearn: 0.2845838\ttotal: 1.81s\tremaining: 2.31s\n",
      "22:\tlearn: 0.2804898\ttotal: 1.87s\tremaining: 2.2s\n",
      "23:\tlearn: 0.2765556\ttotal: 1.94s\tremaining: 2.1s\n",
      "24:\tlearn: 0.2728803\ttotal: 2s\tremaining: 2s\n",
      "25:\tlearn: 0.2693441\ttotal: 2.06s\tremaining: 1.9s\n",
      "26:\tlearn: 0.2655750\ttotal: 2.13s\tremaining: 1.81s\n",
      "27:\tlearn: 0.2619450\ttotal: 2.19s\tremaining: 1.72s\n",
      "28:\tlearn: 0.2584877\ttotal: 2.25s\tremaining: 1.63s\n",
      "29:\tlearn: 0.2547024\ttotal: 2.32s\tremaining: 1.55s\n",
      "30:\tlearn: 0.2511420\ttotal: 2.39s\tremaining: 1.47s\n",
      "31:\tlearn: 0.2486533\ttotal: 2.45s\tremaining: 1.38s\n",
      "32:\tlearn: 0.2453341\ttotal: 2.52s\tremaining: 1.3s\n",
      "33:\tlearn: 0.2427064\ttotal: 2.58s\tremaining: 1.22s\n",
      "34:\tlearn: 0.2405744\ttotal: 2.65s\tremaining: 1.14s\n",
      "35:\tlearn: 0.2377927\ttotal: 2.72s\tremaining: 1.06s\n",
      "36:\tlearn: 0.2356802\ttotal: 2.79s\tremaining: 980ms\n",
      "37:\tlearn: 0.2327598\ttotal: 2.85s\tremaining: 901ms\n",
      "38:\tlearn: 0.2307260\ttotal: 2.91s\tremaining: 822ms\n",
      "39:\tlearn: 0.2278309\ttotal: 2.98s\tremaining: 745ms\n",
      "40:\tlearn: 0.2262529\ttotal: 3.05s\tremaining: 670ms\n",
      "41:\tlearn: 0.2241074\ttotal: 3.12s\tremaining: 595ms\n",
      "42:\tlearn: 0.2216142\ttotal: 3.18s\tremaining: 518ms\n",
      "43:\tlearn: 0.2196829\ttotal: 3.24s\tremaining: 442ms\n",
      "44:\tlearn: 0.2169899\ttotal: 3.31s\tremaining: 367ms\n",
      "45:\tlearn: 0.2152857\ttotal: 3.37s\tremaining: 293ms\n",
      "46:\tlearn: 0.2127822\ttotal: 3.44s\tremaining: 219ms\n",
      "47:\tlearn: 0.2112916\ttotal: 3.5s\tremaining: 146ms\n",
      "48:\tlearn: 0.2093257\ttotal: 3.57s\tremaining: 72.8ms\n",
      "49:\tlearn: 0.2078152\ttotal: 3.63s\tremaining: 0us\n",
      "Accuracy: 0.8713745271122321\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=50,\n",
    "                           depth=10,\n",
    "                           learning_rate=0.5,\n",
    "                           loss_function='MultiClass',\n",
    "                           verbose=True)\n",
    "\n",
    "model.fit(X_train, y_sex_train)\n",
    "preds = model.predict(X_test)\n",
    "model.save_model('gender_model.pth')\n",
    "\n",
    "print(\"Accuracy:\", np.mean(preds.flatten() == y_sex_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9430487\ttotal: 116ms\tremaining: 5.7s\n",
      "1:\tlearn: 0.8600838\ttotal: 364ms\tremaining: 8.75s\n",
      "2:\tlearn: 0.8099983\ttotal: 477ms\tremaining: 7.46s\n",
      "3:\tlearn: 0.7655609\ttotal: 572ms\tremaining: 6.58s\n",
      "4:\tlearn: 0.7340628\ttotal: 668ms\tremaining: 6.01s\n",
      "5:\tlearn: 0.7080299\ttotal: 760ms\tremaining: 5.58s\n",
      "6:\tlearn: 0.6856652\ttotal: 854ms\tremaining: 5.24s\n",
      "7:\tlearn: 0.6621763\ttotal: 947ms\tremaining: 4.97s\n",
      "8:\tlearn: 0.6434215\ttotal: 1.04s\tremaining: 4.73s\n",
      "9:\tlearn: 0.6284765\ttotal: 1.13s\tremaining: 4.52s\n",
      "10:\tlearn: 0.6149471\ttotal: 1.22s\tremaining: 4.33s\n",
      "11:\tlearn: 0.6043125\ttotal: 1.31s\tremaining: 4.17s\n",
      "12:\tlearn: 0.5943439\ttotal: 1.41s\tremaining: 4.02s\n",
      "13:\tlearn: 0.5827502\ttotal: 1.51s\tremaining: 3.87s\n",
      "14:\tlearn: 0.5734437\ttotal: 1.6s\tremaining: 3.74s\n",
      "15:\tlearn: 0.5626220\ttotal: 1.69s\tremaining: 3.6s\n",
      "16:\tlearn: 0.5526726\ttotal: 1.78s\tremaining: 3.46s\n",
      "17:\tlearn: 0.5457675\ttotal: 1.87s\tremaining: 3.33s\n",
      "18:\tlearn: 0.5367592\ttotal: 1.96s\tremaining: 3.21s\n",
      "19:\tlearn: 0.5271919\ttotal: 2.06s\tremaining: 3.08s\n",
      "20:\tlearn: 0.5183843\ttotal: 2.16s\tremaining: 2.98s\n",
      "21:\tlearn: 0.5099078\ttotal: 2.25s\tremaining: 2.86s\n",
      "22:\tlearn: 0.5010762\ttotal: 2.34s\tremaining: 2.75s\n",
      "23:\tlearn: 0.4938857\ttotal: 2.44s\tremaining: 2.64s\n",
      "24:\tlearn: 0.4858578\ttotal: 2.54s\tremaining: 2.54s\n",
      "25:\tlearn: 0.4766724\ttotal: 2.64s\tremaining: 2.44s\n",
      "26:\tlearn: 0.4711465\ttotal: 2.74s\tremaining: 2.33s\n",
      "27:\tlearn: 0.4652522\ttotal: 2.83s\tremaining: 2.23s\n",
      "28:\tlearn: 0.4600739\ttotal: 2.93s\tremaining: 2.12s\n",
      "29:\tlearn: 0.4542967\ttotal: 3.03s\tremaining: 2.02s\n",
      "30:\tlearn: 0.4486795\ttotal: 3.12s\tremaining: 1.92s\n",
      "31:\tlearn: 0.4431234\ttotal: 3.22s\tremaining: 1.81s\n",
      "32:\tlearn: 0.4376946\ttotal: 3.31s\tremaining: 1.71s\n",
      "33:\tlearn: 0.4327970\ttotal: 3.41s\tremaining: 1.6s\n",
      "34:\tlearn: 0.4284715\ttotal: 3.5s\tremaining: 1.5s\n",
      "35:\tlearn: 0.4229504\ttotal: 3.59s\tremaining: 1.4s\n",
      "36:\tlearn: 0.4185167\ttotal: 3.69s\tremaining: 1.3s\n",
      "37:\tlearn: 0.4138708\ttotal: 3.78s\tremaining: 1.19s\n",
      "38:\tlearn: 0.4092469\ttotal: 3.87s\tremaining: 1.09s\n",
      "39:\tlearn: 0.4046677\ttotal: 3.96s\tremaining: 991ms\n",
      "40:\tlearn: 0.4016154\ttotal: 4.06s\tremaining: 891ms\n",
      "41:\tlearn: 0.3977743\ttotal: 4.15s\tremaining: 790ms\n",
      "42:\tlearn: 0.3950115\ttotal: 4.24s\tremaining: 690ms\n",
      "43:\tlearn: 0.3911067\ttotal: 4.33s\tremaining: 591ms\n",
      "44:\tlearn: 0.3868696\ttotal: 4.42s\tremaining: 492ms\n",
      "45:\tlearn: 0.3833408\ttotal: 4.52s\tremaining: 393ms\n",
      "46:\tlearn: 0.3779889\ttotal: 4.61s\tremaining: 294ms\n",
      "47:\tlearn: 0.3742800\ttotal: 4.7s\tremaining: 196ms\n",
      "48:\tlearn: 0.3703780\ttotal: 4.79s\tremaining: 97.8ms\n",
      "49:\tlearn: 0.3666751\ttotal: 4.88s\tremaining: 0us\n",
      "Accuracy: 0.7477931904161412\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=50,\n",
    "                           depth=10,\n",
    "                           learning_rate=0.5,\n",
    "                           loss_function='MultiClass',\n",
    "                           verbose=True)\n",
    "\n",
    "model.fit(X_train, y_age_train)\n",
    "preds = model.predict(X_test)\n",
    "model.save_model('age_model.pth')\n",
    "\n",
    "print(\"Accuracy:\", np.mean(preds.flatten() == y_age_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
